{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Split"
      ],
      "metadata": {
        "id": "93wT8KPeRJKC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Kk0_gnXZPhu5"
      },
      "outputs": [],
      "source": [
        "# importing essential libraries which we needed while doing task\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Sourav20341/ML/main/.github/workflows/Real%20estate.csv\")\n",
        "X = df.iloc[:,1:-1].values;  # This split all the features from output column\n",
        "Y = np.reshape(df.iloc[:,-1].values,(-1,1)); # This gives us the output column and we are converting in 2D matrix with the help of reshape for our ease of computation\n",
        "mean_X = np.mean(X,axis = 0)  # Calculating Mean of Features\n",
        "std_X = np.std(X,axis = 0)  # Calculating Standard Deviation of Feautres\n",
        "size_Y = Y.shape # Storing dimesions of Output Column\n",
        "\n",
        "#Normalisation of Features Data\n",
        "for i in range(size_X[1]):\n",
        "  for j in range(size_X[0]):\n",
        "    X[j][i] = X[j][i] - mean_X[i]\n",
        "    X[j][i] = X[j][i]/std_X[i]\n",
        "\n",
        "\n",
        "#insert a column in input matrix for w0 weight\n",
        "X = np.insert(X,0,1,axis = 1) # inserting a column for bias\n",
        "size_X = X.shape # Storing dimension of Features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting Data\n"
      ],
      "metadata": {
        "id": "kozosChI_45t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are splitting the data for each K fold range from 2 to 5 and stores in variable\n",
        "\n",
        "# k = 2\n",
        "\n",
        "X_train21 = X[:int(size_X[0]/2),:]\n",
        "X_train22 = X[int(size_X[0]/2):,:]\n",
        "Y_train21 = Y[:int(size_Y[0]/2)]\n",
        "Y_train22 = Y[int(size_Y[0]/2):]\n",
        "\n",
        "# k = 3\n",
        "\n",
        "X_train31 = X[:int(size_X[0]/3),:]\n",
        "X_train32 = X[int(size_X[0]/3):int(2*size_X[0]/3),:]\n",
        "X_train33 = X[int(2*size_X[0]/3):,:]\n",
        "Y_train31 = Y[:int(size_Y[0]/3)]\n",
        "Y_train32 = Y[int(size_Y[0]/3):int(2*size_Y[0]/3)]\n",
        "Y_train33 = Y[int(2*size_Y[0]/3):]\n",
        "\n",
        "# k = 4\n",
        "\n",
        "X_train41 = X[:int(size_X[0]/4),:]\n",
        "X_train42 = X[int(size_X[0]/4):int(size_X[0]/2),:]\n",
        "X_train43 = X[int(size_X[0]/2):int(3*size_X[0]/4),:]\n",
        "X_train44 = X[int(3*size_X[0]/4):,:]\n",
        "Y_train41 = Y[:int(size_Y[0]/4)]\n",
        "Y_train42 = Y[int(size_Y[0]/4):int(size_Y[0]/2)]\n",
        "Y_train43 = Y[int(size_Y[0]/2):int(3*size_Y[0]/4)]\n",
        "Y_train44 = Y[int(3*size_Y[0]/4):]\n",
        "\n",
        "# k = 5\n",
        "\n",
        "X_train51 = X[:int(size_X[0]/5),:]\n",
        "X_train52 = X[int(size_X[0]/5):int(2*size_X[0]/5),:]\n",
        "X_train53 = X[int(2*size_X[0]/5):int(3*size_X[0]/5),:]\n",
        "X_train54 = X[int(3*size_X[0]/5):int(4*size_X[0]/5),:]\n",
        "X_train55 = X[int(4*size_X[0]/5):,:]\n",
        "Y_train51 = Y[:int(size_Y[0]/5)]\n",
        "Y_train52 = Y[int(size_Y[0]/5):int(2*size_Y[0]/5)]\n",
        "Y_train53 = Y[int(2*size_Y[0]/5):int(3*size_Y[0]/5)]\n",
        "Y_train54 = Y[int(3*size_Y[0]/5):int(4*size_Y[0]/5)]\n",
        "Y_train55 = Y[int(4*size_Y[0]/5):]"
      ],
      "metadata": {
        "id": "eRTKQpXF_34D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression Gradient Descent "
      ],
      "metadata": {
        "id": "iy-31dcJHTv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are implementing Gradient Descent function,root mean square function, mean square function, Transpose function\n",
        "\n",
        "def rmse(y_expected,y_pred):  # this returns root mean square value\n",
        "  val = mse(y_expected,y_pred)\n",
        "  return math.sqrt(val)\n",
        "\n",
        "def mse(y_expected,y_pred):  # this returns mean square value\n",
        "  size = y_expected.size\n",
        "  J = 0\n",
        "  for i in range(size):\n",
        "    J += (y_expected[i] - y_pred[i])**2\n",
        "  J = J/size\n",
        "  return J\n",
        "\n",
        "def Transpose(array):  # this transpose the array\n",
        "  n,m = array.shape\n",
        "  res = np.zeros((m,n))\n",
        "  for i in range(n):\n",
        "    for j in range(m):\n",
        "      res[j][i] = array[i][j]\n",
        "  return res\n",
        "  \n",
        "def DescentGradient(X,Y,epoch=1300,p = False,model_num = 0):  # this returns the weight \n",
        "  RMSE = []          # this array stores the root mean square value at each iteration\n",
        "  Iteration_Number = [] # this array stores the iteration number at each iteration\n",
        "  alpha = 0.006  # this is our learning rate\n",
        "  weight = np.zeros((1,7)) # intialising weight array \n",
        "  for i in range(7):\n",
        "    weight[0,i] = 2\n",
        "  for i in range(epoch):\n",
        "    T = Transpose(weight)   # transposing the weight matrix\n",
        "    sumpart = np.matmul(X,T) - Y  # we are multiplying Transpose of weight with features and minus it with output\n",
        "    cost = np.sum(X*sumpart,axis = 0)/X.shape[0]  # this gives us the cost \n",
        "    weight = weight - alpha*cost  # this updates the weight according to gradient descent \n",
        "    RMSE = np.append(RMSE,rmse(Y,np.matmul(X,T)))  # store the current rmse in array\n",
        "    Iteration_Number = np.append(Iteration_Number,i) # store the iteration in array\n",
        "  if(p):\n",
        "    # below code is for ploting the graph\n",
        "    s = \"Model \" + str(model_num)\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"RMSE\")\n",
        "    plt.plot(Iteration_Number,RMSE,label = s)\n",
        "    plt.legend()\n",
        "  return weight;  # returning the weight"
      ],
      "metadata": {
        "id": "lzn6_6VjRdeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Root Mean Error Count for all values of K"
      ],
      "metadata": {
        "id": "awG-OphDfxvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this Code block we are only calculating rmse for each K and find mean rmse for each k and reporting it by print the error and also we are using vstack\n",
        "# for concatenation the 2 matrix because we are joing k-1 matrix for training and other matrix for testing\n",
        "\n",
        "# k = 2\n",
        "\n",
        "wt21 = DescentGradient(X_train21,Y_train21)\n",
        "error21 = rmse(Y_train22,np.matmul(X_train22,Transpose(wt21)))\n",
        "wt22 = DescentGradient(X_train22,Y_train22)\n",
        "error22 = rmse(Y_train21,np.matmul(X_train21,Transpose(wt22)))\n",
        "meanerror2 = (error21+error22)/2\n",
        "print(\"Mean RMSE for K = 2 :- \" +  str(meanerror2))\n",
        "\n",
        "# k = 3\n",
        "\n",
        "wt31 = DescentGradient(np.vstack((X_train31,X_train32)),np.vstack((Y_train31,Y_train32)))\n",
        "error31 = rmse(Y_train33,np.matmul(X_train33,Transpose(wt31)))\n",
        "wt32 = DescentGradient(np.vstack((X_train31,X_train33)),np.vstack((Y_train31,Y_train33)))\n",
        "error32 = rmse(Y_train32,np.matmul(X_train32,Transpose(wt32)))\n",
        "wt33 = DescentGradient(np.vstack((X_train32,X_train33)),np.vstack((Y_train32,Y_train33)))\n",
        "error33 = rmse(Y_train31,np.matmul(X_train31,Transpose(wt33)))\n",
        "meanerror3 = (error31+error32+error33)/3\n",
        "print(\"Mean RMSE for K = 3 :- \" + str(meanerror3))\n",
        "\n",
        "# k = 4\n",
        "\n",
        "wt41 = DescentGradient(np.vstack((np.vstack((X_train41,X_train42)),X_train43)),np.vstack((np.vstack((Y_train41,Y_train42)),Y_train43)))\n",
        "error41 = rmse(Y_train44,np.matmul(X_train44,Transpose(wt41)))\n",
        "wt42 = DescentGradient(np.vstack((np.vstack((X_train41,X_train42)),X_train44)),np.vstack((np.vstack((Y_train41,Y_train42)),Y_train44)))\n",
        "error42 = rmse(Y_train43,np.matmul(X_train43,Transpose(wt42)))\n",
        "wt43 = DescentGradient(np.vstack((np.vstack((X_train41,X_train43)),X_train44)),np.vstack((np.vstack((Y_train41,Y_train43)),Y_train44)))\n",
        "error43 = rmse(Y_train42,np.matmul(X_train42,Transpose(wt43)))\n",
        "wt44 = DescentGradient(np.vstack((np.vstack((X_train42,X_train43)),X_train44)),np.vstack((np.vstack((Y_train42,Y_train43)),Y_train44)))\n",
        "error44 = rmse(Y_train41,np.matmul(X_train41,Transpose(wt44)))\n",
        "meanerror4 = (error41+error42+error43+error44)/4\n",
        "print(\"Mean RMSE for K = 4 :- \"+str(meanerror4))\n",
        "\n",
        "# k = 5\n",
        "\n",
        "trainingSet51_X = np.vstack((np.vstack((np.vstack((X_train51,X_train52)),X_train53)),X_train54))\n",
        "trainingSet51_Y = np.vstack((np.vstack((np.vstack((Y_train51,Y_train52)),Y_train53)),Y_train54))\n",
        "wt51 = DescentGradient(trainingSet51_X,trainingSet51_Y)\n",
        "error51 = rmse(Y_train55,np.matmul(X_train55,Transpose(wt51)))\n",
        "error51t = rmse(trainingSet51_Y,np.matmul(trainingSet51_X,Transpose(wt51)))\n",
        "\n",
        "trainingSet52_X = np.vstack((np.vstack((np.vstack((X_train51,X_train52)),X_train53)),X_train55))\n",
        "trainingSet52_Y = np.vstack((np.vstack((np.vstack((Y_train51,Y_train52)),Y_train53)),Y_train55))\n",
        "wt52 = DescentGradient(trainingSet52_X,trainingSet52_Y)\n",
        "error52 = rmse(Y_train54,np.matmul(X_train54,Transpose(wt52)))\n",
        "error52t = rmse(trainingSet52_Y,np.matmul(trainingSet52_X,Transpose(wt52)))\n",
        "\n",
        "trainingSet53_X = np.vstack((np.vstack((np.vstack((X_train51,X_train52)),X_train54)),X_train55))\n",
        "trainingSet53_Y = np.vstack((np.vstack((np.vstack((Y_train51,Y_train52)),Y_train54)),Y_train55))\n",
        "wt53 = DescentGradient(trainingSet53_X,trainingSet53_Y)\n",
        "error53 = rmse(Y_train53,np.matmul(X_train53,Transpose(wt53)))\n",
        "error53t = rmse(trainingSet53_Y,np.matmul(trainingSet53_X,Transpose(wt53)))\n",
        "\n",
        "trainingSet54_X = np.vstack((np.vstack((np.vstack((X_train51,X_train53)),X_train54)),X_train55))\n",
        "trainingSet54_Y = np.vstack((np.vstack((np.vstack((Y_train51,Y_train53)),Y_train54)),Y_train55))\n",
        "wt54 = DescentGradient(trainingSet54_X,trainingSet54_Y)\n",
        "error54 = rmse(Y_train52,np.matmul(X_train52,Transpose(wt54)))\n",
        "error54t = rmse(trainingSet54_Y,np.matmul(trainingSet54_X,Transpose(wt54)))\n",
        "\n",
        "trainingSet55_X = np.vstack((np.vstack((np.vstack((X_train52,X_train53)),X_train54)),X_train55))\n",
        "trainingSet55_Y = np.vstack((np.vstack((np.vstack((Y_train52,Y_train53)),Y_train54)),Y_train55))\n",
        "wt55 = DescentGradient(trainingSet55_X,trainingSet55_Y)\n",
        "error55 = rmse(Y_train51,np.matmul(X_train51,Transpose(wt55)))\n",
        "error55t = rmse(trainingSet55_Y,np.matmul(trainingSet55_X,Transpose(wt55)))\n",
        "meanerror5 = (error51+error52+error53+error54+error55)/5\n",
        "print(\"Mean RMSE for K = 5 :- \" + str(meanerror5))"
      ],
      "metadata": {
        "id": "d24pwJGZfw4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting"
      ],
      "metadata": {
        "id": "w9K1OvF963ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are reporting the train and set val loss and with that we are also ploting rmse vs iteation graph for k = 5 which we find optimal from pevious part\n",
        "\n",
        "wt51 = DescentGradient(trainingSet51_X,trainingSet51_Y,p = True,model_num = 1)\n",
        "error51 = rmse(Y_train55,np.matmul(X_train55,Transpose(wt51)))\n",
        "error51t = rmse(trainingSet51_Y,np.matmul(trainingSet51_X,Transpose(wt51)))\n",
        "# print(error51)\n",
        "# print(error51t)\n",
        "\n",
        "wt52 = DescentGradient(trainingSet52_X,trainingSet52_Y,p=True,model_num = 2)\n",
        "error52 = rmse(Y_train54,np.matmul(X_train54,Transpose(wt52)))\n",
        "error52t = rmse(trainingSet52_Y,np.matmul(trainingSet52_X,Transpose(wt52)))\n",
        "# print(error52t)\n",
        "# print(error52)\n",
        "\n",
        "wt53 = DescentGradient(trainingSet53_X,trainingSet53_Y,p=True,model_num = 3)\n",
        "error53 = rmse(Y_train53,np.matmul(X_train53,Transpose(wt53)))\n",
        "error53t = rmse(trainingSet53_Y,np.matmul(trainingSet53_X,Transpose(wt53)))\n",
        "# print(error53)\n",
        "# print(error53t)\n",
        "\n",
        "wt54 = DescentGradient(trainingSet54_X,trainingSet54_Y,p=True,model_num = 4)\n",
        "error54 = rmse(Y_train52,np.matmul(X_train52,Transpose(wt54)))\n",
        "error54t = rmse(trainingSet54_Y,np.matmul(trainingSet54_X,Transpose(wt54)))\n",
        "# print(error54t)\n",
        "# print(error54)\n",
        "\n",
        "wt55 = DescentGradient(trainingSet55_X,trainingSet55_Y,p=True,model_num = 5)\n",
        "error55 = rmse(Y_train51,np.matmul(X_train51,Transpose(wt55)))\n",
        "error55t = rmse(trainingSet55_Y,np.matmul(trainingSet55_X,Transpose(wt55)))\n",
        "meanerror5 = (error51+error52+error53+error54+error55)/5\n",
        "# print(error55t)\n",
        "# print(error55)\n",
        "\n",
        "print(\"Training RMSE for K = 5 :- \"+str((error51t+error52t+error53t+error54t+error55t)/5));\n",
        "print(\"Val Set RMSE for K = 5 :- \" + str(meanerror5))"
      ],
      "metadata": {
        "id": "hpL9xyg862po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ridge Regression"
      ],
      "metadata": {
        "id": "P-iu9R5XH6XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are implementing Ridge_Regression and this is similar to gradient descent but the changes which has been made here is explained\n",
        "\n",
        "def Ridge_Regression(X,Y,epoch=1350,model_num = 0):  \n",
        "  plot = []\n",
        "  plot1 = []\n",
        "  alpha = 0.006\n",
        "  lamb = 0.0055  # regularization perimeter  \n",
        "  weight = np.zeros((1,7))\n",
        "  for i in range(7):\n",
        "    weight[0,i] = 2\n",
        "  for i in range(epoch):\n",
        "    T = Transpose(weight)\n",
        "    sumpart = np.matmul(X,T) - Y\n",
        "    cost = np.sum(X*sumpart,axis = 0)/X.shape[0]\n",
        "    weight = (1-2*lamb*alpha)*weight - 2*alpha*cost   # adding ridge regularization penalty while calculating weight\n",
        "    plot = np.append(plot,rmse(Y,np.matmul(X,T)))\n",
        "    plot1 = np.append(plot1,i)\n",
        "  s = \"Model \" + str(model_num)\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.plot(plot1,plot,label = s)\n",
        "  plt.legend()\n",
        "  return weight;"
      ],
      "metadata": {
        "id": "uKbbtqAwH6BO"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge Plotting"
      ],
      "metadata": {
        "id": "bB6J3mwWG6Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are calculating rmse and find weights with ridge regulrization for each model of k = 5 and reporting the mean rmse on train and val set with that we are ploting the graph\n",
        "\n",
        "# Model1\n",
        "wtR1 = Ridge_Regression(trainingSet51_X,trainingSet51_Y,model_num = 1)\n",
        "errorR1 = rmse(Y_train55,np.matmul(X_train55,Transpose(wtR1)))\n",
        "errorRt1 = rmse(trainingSet51_Y,np.matmul(trainingSet51_X,Transpose(wtR1)))\n",
        "\n",
        "# Model2\n",
        "wtR2 = Ridge_Regression(trainingSet52_X,trainingSet52_Y,model_num = 2)\n",
        "errorR2 = rmse(Y_train54,np.matmul(X_train54,Transpose(wtR2)))\n",
        "errorRt2 = rmse(trainingSet52_Y,np.matmul(trainingSet52_X,Transpose(wtR2)))\n",
        "\n",
        "# Model3\n",
        "wtR3 = Ridge_Regression(trainingSet53_X,trainingSet53_Y,model_num = 3)\n",
        "errorR3 = rmse(Y_train53,np.matmul(X_train53,Transpose(wtR3)))\n",
        "errorRt3 = rmse(trainingSet53_Y,np.matmul(trainingSet53_X,Transpose(wtR3)))\n",
        "\n",
        "\n",
        "# Model4\n",
        "wtR4 = Ridge_Regression(trainingSet54_X,trainingSet54_Y,model_num = 4)\n",
        "errorR4 = rmse(Y_train52,np.matmul(X_train52,Transpose(wtR4)))\n",
        "errorRt4 = rmse(trainingSet54_Y,np.matmul(trainingSet54_X,Transpose(wtR4)))\n",
        "\n",
        "# Model5\n",
        "wtR5 = Ridge_Regression(trainingSet55_X,trainingSet55_Y,model_num = 5)\n",
        "errorR5 = rmse(Y_train51,np.matmul(X_train51,Transpose(wtR5)))\n",
        "errorRt5 = rmse(trainingSet55_Y,np.matmul(trainingSet55_X,Transpose(wtR5)))\n",
        "\n",
        "print(\"Training Error :- \" + str((errorRt1 + errorRt2 + errorRt3 + errorRt4 + errorRt5)/5))\n",
        "print(\"Testing Error :- \" + str((errorR1 + errorR2 + errorR3 + errorR4 + errorR5)/5))"
      ],
      "metadata": {
        "id": "UcZMHbFQZKE8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "1c70f65b-0c7a-4f35-da4c-2be9a32011f5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Error :- 8.768364520982155\n",
            "Testing Error :- 8.69599974745391\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso Regression"
      ],
      "metadata": {
        "id": "eXbp1NnCH9Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are implementing Lasso Regularization and it is very similar to gradient descent\n",
        "\n",
        "def lasso_Regression(X,Y,epoch=1200,model_num = 0):\n",
        "  RMSE = []\n",
        "  Iteration_Count = []\n",
        "  alpha = 0.006 \n",
        "  lamb = 0.0001  # Regularization Perimeter\n",
        "  weight = np.zeros((1,7))\n",
        "  for i in range(7):\n",
        "    weight[0,i] = 2\n",
        "  for i in range(epoch):\n",
        "    T = Transpose(weight)\n",
        "    sumpart = np.matmul(X,T) - Y\n",
        "    cost = np.sum(X*sumpart,axis = 0)/X.shape[0]\n",
        "    weight = weight - alpha*cost + lamb*np.sum(weight/np.abs(weight))  # adding lasso regularization penatly while calculating the weights\n",
        "    RMSE = np.append(RMSE,rmse(Y,np.matmul(X,T)))\n",
        "    Iteration_Count = np.append(Iteration_Count,i)\n",
        "  s = \"Model \" + str(model_num)\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.plot(Iteration_Count,RMSE,label = s)\n",
        "  plt.legend()\n",
        "  return weight;"
      ],
      "metadata": {
        "id": "BUy4rSOiH8qe"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso Ploting"
      ],
      "metadata": {
        "id": "fGSahjJLYDew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are calculating rmse and find weights with lasso regulrization for each model of k = 5 and reporting the mean rmse on train and val set with that we are ploting the graph\n",
        "\n",
        "# Model1\n",
        "wtl1 = lasso_Regression(trainingSet51_X,trainingSet51_Y,model_num = 1)\n",
        "errorl1 = rmse(Y_train55,np.matmul(X_train55,Transpose(wtl1)))\n",
        "errorlt1 = rmse(trainingSet51_Y,np.matmul(trainingSet51_X,Transpose(wtl1)))\n",
        "\n",
        "# Model2\n",
        "wtl2 = lasso_Regression(trainingSet52_X,trainingSet52_Y,model_num = 2)\n",
        "errorl2 = rmse(Y_train54,np.matmul(X_train54,Transpose(wtl2)))\n",
        "errorlt2 = rmse(trainingSet52_Y,np.matmul(trainingSet52_X,Transpose(wtl2)))\n",
        "\n",
        "# Model3\n",
        "wtl3 = lasso_Regression(trainingSet53_X,trainingSet53_Y,model_num = 3)\n",
        "errorl3 = rmse(Y_train53,np.matmul(X_train53,Transpose(wtl3)))\n",
        "errorlt3 = rmse(trainingSet53_Y,np.matmul(trainingSet53_X,Transpose(wtl3)))\n",
        "\n",
        "\n",
        "# Model4\n",
        "wtl4 = lasso_Regression(trainingSet54_X,trainingSet54_Y,model_num = 4)\n",
        "errorl4 = rmse(Y_train52,np.matmul(X_train52,Transpose(wtl4)))\n",
        "errorlt4 = rmse(trainingSet54_Y,np.matmul(trainingSet54_X,Transpose(wtl4)))\n",
        "\n",
        "# Model5\n",
        "wtl5 = lasso_Regression(trainingSet55_X,trainingSet55_Y,model_num = 5)\n",
        "errorl5 = rmse(Y_train51,np.matmul(X_train51,Transpose(wtl5)))\n",
        "errorlt5 = rmse(trainingSet55_Y,np.matmul(trainingSet55_X,Transpose(wtl5)))\n",
        "\n",
        "print(\"Training Error :- \" + str((errorlt1 + errorlt2 + errorlt3 + errorlt4 + errorlt5)/5))\n",
        "print(\"Testing Error :- \" + str((errorl1 + errorl2 + errorl3 + errorl4 + errorl5)/5))"
      ],
      "metadata": {
        "id": "hjh_5l1sYCBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal Equation Function"
      ],
      "metadata": {
        "id": "G0istvveG3iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are implementing Normal Form of Linear regression which is (Xtranspose * X)-1 . (Xtranspose * Y)\n",
        "\n",
        "def NoramlEquation(X,Y):\n",
        "  trans = Transpose(X)  # Transposing X matrix\n",
        "  x = np.matmul(trans,X) # multiply Transpose of X with X\n",
        "  inv = np.linalg.inv(x) # inverse the resultant of multiplication\n",
        "  xTy = np.matmul(trans,Y) # Multiplying transpose of X with Y\n",
        "  weight = np.matmul(inv,xTy) # multiplying inverse matrix with resultant which we get from above multiplication\n",
        "  return weight # return weights after all operation perform"
      ],
      "metadata": {
        "id": "NOuMHbI2GVq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal Equation for Optimal K which is 5"
      ],
      "metadata": {
        "id": "Pzuv_m9KDL7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this code block we are calculating Mean Rmse for k = 5\n",
        "\n",
        "wtN1 = NoramlEquation(trainingSet51_X,trainingSet51_Y)\n",
        "errorN1 = rmse(Y_train55,np.matmul(X_train55,wtN1))\n",
        "# print(errorN1)\n",
        "\n",
        "wtN2 = NoramlEquation(trainingSet52_X,trainingSet52_Y)\n",
        "errorN2 = rmse(Y_train54,np.matmul(X_train54,wtN2))\n",
        "# print(errorN2)\n",
        "\n",
        "wtN3 = NoramlEquation(trainingSet53_X,trainingSet53_Y)\n",
        "errorN3 = rmse(Y_train53,np.matmul(X_train53,wtN3))\n",
        "# print(errorN3)\n",
        "\n",
        "wtN4 = NoramlEquation(trainingSet54_X,trainingSet54_Y)\n",
        "errorN4 = rmse(Y_train52,np.matmul(X_train52,wtN4))\n",
        "# print(errorN4)\n",
        "\n",
        "wtN5 = NoramlEquation(trainingSet55_X,trainingSet55_Y)\n",
        "errorN5 = rmse(Y_train51,np.matmul(X_train51,wtN5))\n",
        "# print(errorN5)\n",
        "\n",
        "print((errorN1 + errorN2 + errorN3 + errorN4 + errorN5)/5)"
      ],
      "metadata": {
        "id": "enxs_4i_DVxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}